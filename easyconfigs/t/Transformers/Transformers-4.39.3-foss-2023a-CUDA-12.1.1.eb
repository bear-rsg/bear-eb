easyblock = 'PythonBundle'

name = 'Transformers'
version = '4.39.3'
versionsuffix = '-CUDA-%(cudaver)s'

homepage = 'https://github.com/huggingface/transformers'
description = """State-of-the-art Natural Language Processing for PyTorch and TensorFlow 2.0"""

toolchain = {'name': 'foss', 'version': '2023a'}

dependencies = [
    ('CUDA', '12.1.1', '', True),
    ('Python', '3.11.3'),
    ('SciPy-bundle', '2023.07'),
    ('PyTorch', '2.1.2', versionsuffix),
    ('PyTorch-bundle', '2.1.2', versionsuffix),
    ('PyYAML', '6.0'),
    ('tqdm', '4.66.1'),
    ('tokenizers', '0.15.2'),
    ('Safetensors', '0.4.3'),
]

use_pip = True
sanity_pip_check = True

exts_list = [
    ('regex', '2023.12.25', {
        'checksums': ['29171aa128da69afdf4bde412d5bedc335f2ca8fcfe4489038577d05f16181e5'],
    }),
    ('%(namelower)s', version, {
        'use_pip_extras': 'torch',
        'checksums': ['2586e5ff4150f122716fc40f5530e92871befc051848fbe82600969c535b762d'],
    }),
]

sanity_check_commands = [
    "python -c 'from transformers import AutoTokenizer'",
]

moduleclass = 'math'
